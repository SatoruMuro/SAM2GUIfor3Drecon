{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhtOhGCXaq5J"
      },
      "source": [
        "# 【使い方】\n",
        "\n",
        "ランタイム>すべてのセルを実行（**Ctrl+F9**）によりすべてのセルを実行し、セル[2]の最後に生成された**URL（Running on public URL）をクリック**して開いてください。（GUIが新しいタブで開かれる）\n",
        "\n",
        "※セル[1]は実行完了までに約5分、セル[2]は5秒程度を要します。\n",
        "\n",
        "※このcolabの画面（タブ）は閉じないでください。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# [How to use]\n",
        "\n",
        "Run all cells by selecting Runtime > Run all cells (**Ctrl+F9**), and **click the URL generated at the end of Cell [2] (Running on public URL)** to open it. (The GUI will open in a new tab)\n",
        "\n",
        "Note: Cell [1] takes about 5 minutes to complete, and Cell [2] takes around 5 seconds.\n",
        "\n",
        "Note: Please do not close this Colab screen (tab)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PW6IU8GdB69j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d55f01-61f0-457c-807c-73501844c982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.1+cu124\n",
            "Torchvision version: 0.20.1+cu124\n",
            "CUDA is available: True\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Collecting git+https://github.com/facebookresearch/sam2.git\n",
            "  Cloning https://github.com/facebookresearch/sam2.git to /tmp/pip-req-build-lpe7aemc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/sam2.git /tmp/pip-req-build-lpe7aemc\n",
            "  Resolved https://github.com/facebookresearch/sam2.git to commit 2b90b9f5ceec907a1c18123530e92e794ad901a4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.20.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (1.26.4)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.67.1)\n",
            "Collecting hydra-core>=1.3.2 (from SAM-2==1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting iopath>=0.1.10 (from SAM-2==1.0)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (11.1.0)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->SAM-2==1.0)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->SAM-2==1.0)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (24.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (4.12.2)\n",
            "Collecting portalocker (from iopath>=0.1.10->SAM-2==1.0)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->SAM-2==1.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->SAM-2==1.0) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: SAM-2, antlr4-python3-runtime, iopath\n",
            "  Building wheel for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SAM-2: filename=SAM_2-1.0-cp311-cp311-linux_x86_64.whl size=470987 sha256=cc888d342c3807590aaddd823cf13d39e947618835829579459e0d1411fb8cd0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fju7a4u9/wheels/d8/63/41/d37b316a85599f58a42be0210805ecf8594b9c06082028716e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=801bebbc559c62d066b483b45e481ab793e530ea8043a5c0a972726906fd77f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=0de415f5727bc54a51a3c0d8c93ecbd4a46c4313148a0bcf0d90f35285bd730b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built SAM-2 antlr4-python3-runtime iopath\n",
            "Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, hydra-core, nvidia-cusolver-cu12, SAM-2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed SAM-2-1.0 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 iopath-0.1.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 portalocker-3.1.1\n",
            "--2025-02-04 05:02:04--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.239.50.120, 18.239.50.18, 18.239.50.9, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.239.50.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 898083611 (856M) [application/vnd.snesdev-page-table]\n",
            "Saving to: ‘../checkpoints/sam2.1_hiera_large.pt’\n",
            "\n",
            "sam2.1_hiera_large. 100%[===================>] 856.48M  73.2MB/s    in 9.1s    \n",
            "\n",
            "2025-02-04 05:02:13 (94.0 MB/s) - ‘../checkpoints/sam2.1_hiera_large.pt’ saved [898083611/898083611]\n",
            "\n",
            "--2025-02-04 05:02:14--  https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2.1/sam2.1_hiera_l.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3798 (3.7K) [text/plain]\n",
            "Saving to: ‘../configs/sam2.1_hiera_l.yaml’\n",
            "\n",
            "sam2.1_hiera_l.yaml 100%[===================>]   3.71K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-04 05:02:14 (59.4 MB/s) - ‘../configs/sam2.1_hiera_l.yaml’ saved [3798/3798]\n",
            "\n",
            "using device: cuda\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.14.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.0 (from gradio)\n",
            "  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.14.0-py3-none-any.whl (57.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.8 ffmpy-0.5.0 gradio-5.14.0 gradio-client-1.7.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.4 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n",
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: svgwrite\n",
            "Successfully installed svgwrite-1.4.3\n"
          ]
        }
      ],
      "source": [
        "using_colab = True\n",
        "\n",
        "if using_colab:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "    print(\"Torchvision version:\", torchvision.__version__)\n",
        "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install opencv-python matplotlib\n",
        "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/sam2.git'\n",
        "\n",
        "    !mkdir -p ../checkpoints/\n",
        "    !wget -P ../checkpoints/ https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\n",
        "\n",
        "    !mkdir -p ../configs/\n",
        "    !wget -P ../configs/ https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2.1/sam2.1_hiera_l.yaml\n",
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"using device: {device}\")\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    torch.autocast(\"cuda\", dtype=torch.float16).__enter__()\n",
        "    if torch.cuda.get_device_properties(0).major >= 8:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "elif device.type == \"mps\":\n",
        "    print(\n",
        "        \"\\nMPSデバイスのサポートは初期段階です。SAM 2はCUDA向けにトレーニングされており、MPS上での数値結果や性能が異なる場合があります。\"\n",
        "    )\n",
        "\n",
        "from sam2.build_sam import build_sam2_video_predictor\n",
        "sam2_checkpoint = \"../checkpoints/sam2.1_hiera_large.pt\"\n",
        "model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
        "predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint, device=device)\n",
        "\n",
        "!pip install transformers huggingface_hub gradio\n",
        "!pip install svgwrite numpy opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRbWQtgf0j2G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "681a6bb9-a81a-43ec-8e29-1f04e5be8237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a84499da80ef6807f5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a84499da80ef6807f5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import tempfile\n",
        "import zipfile\n",
        "from io import BytesIO\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# スクリプト冒頭で starting_index を初期化\n",
        "starting_index = 0\n",
        "\n",
        "# アップロードされたJPEG画像ファイル名と画像データを保存するリスト\n",
        "uploaded_images = []\n",
        "\n",
        "# 色ラベル一覧 (RGB版)\n",
        "color_labels = [\n",
        "    (255, 0, 0), (0, 0, 255), (0, 255, 0), (255, 255, 0),\n",
        "    (128, 0, 128), (255, 165, 0), (0, 255, 255), (173, 255, 47),\n",
        "    (128, 128, 128), (0, 128, 128), (255, 192, 203), (255, 20, 147),\n",
        "    (0, 128, 0), (128, 0, 0), (0, 255, 230), (255, 215, 0),\n",
        "    (255, 69, 0), (0, 0, 128), (220, 20, 60), (128, 128, 0)\n",
        "]\n",
        "\n",
        "# 座標とラベルを保持するリスト\n",
        "stored_points = []\n",
        "# 複数のオブジェクトのセグメンテーションマスクを保持するリスト\n",
        "stored_masks = []\n",
        "# 現在のオブジェクトのマスクを保持するリスト\n",
        "current_mask = None\n",
        "# セグメントしたオブジェクトのリスト\n",
        "object_list = []\n",
        "\n",
        "def convert_image_to_jpeg_if_needed(image):\n",
        "    \"\"\"画像がJPEGでない場合、JPEGに変換して保存する\"\"\"\n",
        "    try:\n",
        "        # 既にJPEG形式であれば変換しない\n",
        "        if isinstance(image, Image.Image):\n",
        "            if image.format == 'JPEG':\n",
        "                print(f\"Image is already in JPEG format.: {image.filename}\")\n",
        "                return image.filename  # JPEG形式ならファイルパスを返す\n",
        "\n",
        "            # JPEGに変換\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False) as tmp_file:\n",
        "                jpeg_image_path = tmp_file.name\n",
        "                image.convert(\"RGB\").save(jpeg_image_path, \"JPEG\")\n",
        "                print(f\"Image converted to JPEG and saved as: {jpeg_image_path}\")\n",
        "                return jpeg_image_path\n",
        "        elif isinstance(image, np.ndarray):\n",
        "            # NumPy配列をJPEGとして保存\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False) as tmp_file:\n",
        "                jpeg_image_path = tmp_file.name\n",
        "                cv2.imwrite(jpeg_image_path, image)\n",
        "                print(f\"NumPy array converted to JPEG and saved as: {jpeg_image_path}\")\n",
        "                return jpeg_image_path\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported image type: {type(image)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in converting image to JPEG: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def upload_images(files):\n",
        "    global uploaded_images, starting_index  # starting_index をグローバル変数として宣言\n",
        "    uploaded_images = []\n",
        "\n",
        "    # ファイル名に基づいてソートし、最小の番号を取得\n",
        "    files = sorted(files, key=lambda f: int(os.path.splitext(os.path.basename(f.name))[0][-4:]))\n",
        "    starting_index = int(os.path.splitext(os.path.basename(files[0].name))[0][-4:])  # 最小番号を取得\n",
        "\n",
        "    # 保存先フォルダの作成\n",
        "    image_save_dir = '/content/images'\n",
        "    if not os.path.exists(image_save_dir):\n",
        "        os.makedirs(image_save_dir)\n",
        "\n",
        "    images_with_filenames = []  # 画像と元のファイル名のペアリスト\n",
        "\n",
        "    for idx, file in enumerate(files):\n",
        "        image = Image.open(file)\n",
        "        original_filename = os.path.basename(file.name)  # 元のファイル名を取得\n",
        "\n",
        "        # 画像フォーマットをデバッグ用に出力\n",
        "        print(f\"Format of uploaded image {idx + 1}: {image.format}\")\n",
        "\n",
        "        # JPEGに変換して保存\n",
        "        jpeg_image_path = convert_image_to_jpeg_if_needed(image)\n",
        "        saved_image_path = os.path.join(image_save_dir, f'image_{idx + 1}.jpg')\n",
        "        image.save(saved_image_path, format=\"JPEG\")\n",
        "        uploaded_images.append(saved_image_path)\n",
        "\n",
        "        # 元のファイル名を付けた画像のペアを追加\n",
        "        images_with_filenames.append((saved_image_path, original_filename))\n",
        "\n",
        "    # アップロードされた画像でmp4動画を作成\n",
        "    video_output_path = \"/content/output_video.mp4\"\n",
        "    create_video_from_images(uploaded_images, video_output_path)\n",
        "\n",
        "    # アップロードが完了した時点で、最初の画像を表示\n",
        "    if uploaded_images:\n",
        "        first_image = uploaded_images[0]\n",
        "    else:\n",
        "        first_image = None\n",
        "\n",
        "    # グローバル変数 uploaded_images のソート済みリストを Gradio ギャラリー用に返す\n",
        "    return (f\"{len(uploaded_images)} images have been uploaded and saved to {image_save_dir}. Video saved to {video_output_path}.\",\n",
        "            gr.update(maximum=len(uploaded_images), value=1),\n",
        "            first_image,\n",
        "            images_with_filenames)  # ギャラリーに画像と元のファイル名のペアを返す\n",
        "\n",
        "def create_video_from_images(image_list, output_video_path, fps=30):\n",
        "    if len(image_list) == 0:\n",
        "        raise ValueError(\"The image list is empty. Please provide at least one image.\")\n",
        "\n",
        "    first_image = cv2.imread(image_list[0])\n",
        "    height, width, _ = first_image.shape\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 出力フォーマット\n",
        "    video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for image_path in image_list:\n",
        "        img = cv2.imread(image_path)\n",
        "        video.write(img)\n",
        "\n",
        "    video.release()\n",
        "\n",
        "def display_image(image_index):\n",
        "    global uploaded_images\n",
        "    if len(uploaded_images) > 0:\n",
        "        image_index = int(image_index) - 1  # スライダーは1から始まるため、インデックスとして使う際は1を引く\n",
        "        if image_index < 0 or image_index >= len(uploaded_images):\n",
        "            return None  # 範囲外の場合は None を返す\n",
        "        return uploaded_images[image_index]\n",
        "    return None\n",
        "\n",
        "# update_result_on_select 関数が表示する画像を「セグメント結果」にも表示させる\n",
        "def update_result_on_select(image_index):\n",
        "    global uploaded_images\n",
        "    if len(uploaded_images) > 0:\n",
        "        image_index = int(image_index) - 1  # スライダーのインデックスに合わせて調整\n",
        "        if image_index < 0 or image_index >= len(uploaded_images):\n",
        "            return None, None  # 範囲外の場合は None を2つ返す\n",
        "\n",
        "        selected_image = uploaded_images[image_index]\n",
        "\n",
        "        # 画像を読み込んで BGR から RGB に変換\n",
        "        image_np = cv2.imread(selected_image)\n",
        "        if image_np is None:\n",
        "            raise ValueError(f\"Failed to load the image.: {selected_image}\")\n",
        "\n",
        "        # BGR から RGB に変換\n",
        "        image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # 初期値として50%の位置にラインを描画して「セグメント結果」に表示\n",
        "        initial_image_with_lines = update_image_with_lines(image_np, 50, 50)\n",
        "\n",
        "        # 選択された画像と、セグメント結果に表示する画像を返す\n",
        "        return image_np, initial_image_with_lines  # 両方の出力を返す\n",
        "    return None, None  # 画像がない場合は None を2つ返す\n",
        "\n",
        "last_used_coords = []  # 座標を複数記録できるようにリストに変更\n",
        "stored_masks = []  # 複数マスクを保持するリスト\n",
        "\n",
        "# AddとRemoveの座標を保持するリスト\n",
        "current_object_points = []  # (x座標, y座標, ラベル) のタプルで保持\n",
        "\n",
        "top_left = None\n",
        "bottom_right = None\n",
        "\n",
        "def set_top_left(x_percent, y_percent):\n",
        "    global top_left\n",
        "    top_left = (x_percent, y_percent)\n",
        "    return f\"Top left set at ({x_percent}, {y_percent})\"\n",
        "\n",
        "def set_bottom_right(x_percent, y_percent, image):\n",
        "    global top_left, bottom_right, predictor, current_mask, stored_masks\n",
        "\n",
        "    # 画像が None の場合はエラーメッセージを返す\n",
        "    if image is None:\n",
        "        print(\"No image provided.\")\n",
        "        return None, \"No image provided. Please upload an image.\"\n",
        "\n",
        "    # 画像がJPEG形式であることを確認し、必要なら変換して一時ディレクトリに保存\n",
        "    jpeg_image_path = convert_image_to_jpeg_if_needed(image)\n",
        "\n",
        "    # JPEGファイルを NumPy 配列に変換\n",
        "    image_np = cv2.imread(jpeg_image_path)\n",
        "    if image_np is None:\n",
        "        raise ValueError(f\"Failed to load the JPEG file: {jpeg_image_path}\")\n",
        "\n",
        "    # 一時ディレクトリに保存されたJPEGファイルを使う\n",
        "    image_dir = tempfile.mkdtemp()  # 一時ディレクトリ作成\n",
        "    image_filename = os.path.join(image_dir, \"0.jpg\")  # フレーム名に「0.jpg」を使用\n",
        "    cv2.imwrite(image_filename, image_np)  # 画像を保存\n",
        "    print(f\"Image saved to: {image_filename}\")\n",
        "\n",
        "    # 右下の座標を設定\n",
        "    bottom_right = (x_percent, y_percent)\n",
        "    print(f\"Bottom-right coordinates set: {bottom_right}\")\n",
        "\n",
        "    # 両方の座標が設定されているか確認\n",
        "    if top_left is not None and bottom_right is not None:\n",
        "        try:\n",
        "            # 画像のサイズを取得\n",
        "            height, width, _ = image_np.shape\n",
        "            print(f\"Image dimensions - Width: {width}, Height: {height}\")\n",
        "\n",
        "            # ボックスの座標をピクセル単位に変換\n",
        "            box = np.array([\n",
        "                int(width * (top_left[0] / 100)), int(height * (top_left[1] / 100)),\n",
        "                int(width * (bottom_right[0] / 100)), int(height * (bottom_right[1] / 100))\n",
        "            ], dtype=np.float32)\n",
        "            print(f\"Box coordinates: {box}\")\n",
        "\n",
        "            # 推論状態の初期化（JPEGファイルをディレクトリから読み込む）\n",
        "            inference_state = predictor.init_state(video_path=image_dir)  # ディレクトリを指定\n",
        "            print(\"Inference state initialized.\")\n",
        "\n",
        "            try:\n",
        "                # ボックスプロンプトを用いたセグメンテーション予測\n",
        "                frame_idx = 0  # フレームインデックスとして整数を指定\n",
        "                _, out_obj_ids, out_mask_logits = predictor.add_new_points_or_box(\n",
        "                    inference_state=inference_state,  # 推論状態\n",
        "                    frame_idx=frame_idx,  # フレームインデックスとして整数を渡す\n",
        "                    obj_id=1,  # オブジェクトID\n",
        "                    box=box  # ボックス座標\n",
        "                )\n",
        "\n",
        "                # マスクを展開し、1次元目を削除して2次元に変換\n",
        "                masks = (out_mask_logits[0] > 0.0).cpu().numpy().squeeze()  # squeeze()で1次元を削除\n",
        "                print(f\"Generated mask shape: {masks.shape}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Segmentation prediction failed: {str(e)}\")\n",
        "                return None, f\"Segmentation prediction failed: {str(e)}\"\n",
        "\n",
        "            # マスクの確認\n",
        "            if masks is None or masks.size == 0:\n",
        "                print(\"No masks were generated.\")\n",
        "                raise ValueError(\"The segmentation mask was not generated.\")\n",
        "\n",
        "            # 現在のマスクを保持\n",
        "            current_mask = masks\n",
        "            print(\"Current mask saved.\")\n",
        "\n",
        "            # 既存のマスクが空かどうか確認\n",
        "            if not stored_masks:\n",
        "                print(\"No previous masks stored.\")\n",
        "            else:\n",
        "                print(f\"Stored masks count: {len(stored_masks)}\")\n",
        "\n",
        "            # 既存のマスクと現在のマスクを合わせて描画\n",
        "            output_image = apply_all_masks2(image_np, stored_masks + [current_mask])\n",
        "            if output_image is not None:\n",
        "                print(\"Mask successfully applied to image.\")\n",
        "            else:\n",
        "                print(\"Mask application to image failed.\")\n",
        "\n",
        "            # 画像データとメッセージを個別に返す\n",
        "            return output_image, \"Segmentation succeeded.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in segmentation process: {str(e)}\")\n",
        "            return None, f\"An error occurred: {str(e)}\"\n",
        "    else:\n",
        "        print(f\"Coordinates not set properly. Top-left: {top_left}, Bottom-right: {bottom_right}\")\n",
        "        return None, \"Please set both top-left and bottom-right coordinates.\"\n",
        "\n",
        "def update_segmentation_result_on_undo(image_np, stored_masks, x_percent, y_percent):\n",
        "    try:\n",
        "        # マスクが適用された画像を生成\n",
        "        output_image = apply_all_masks5(image_np, stored_masks)\n",
        "\n",
        "        # マスク適用後の画像にラインを描画\n",
        "        output_image_with_lines = draw_lines_and_points(output_image, x_percent, y_percent, stored_points)\n",
        "\n",
        "        # 画像を返す\n",
        "        return output_image_with_lines\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in update_segmentation_result_on_undo: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def apply_all_masks5(image, masks):\n",
        "    try:\n",
        "        blended_image = np.array(image, dtype=np.uint8)\n",
        "\n",
        "        for idx, mask in enumerate(masks):\n",
        "            if mask is None or mask.size == 0:\n",
        "                print(f\"The mask was not applied.: {idx}\")\n",
        "                continue  # マスクがない場合はスキップ\n",
        "\n",
        "            # 色ラベルから対応するBGRの色を選択 (最大20個まで対応)\n",
        "            if idx < len(color_labels):\n",
        "                color_bgr = color_labels[idx]  # 色ラベルリストからBGRの色をそのまま使用\n",
        "            else:\n",
        "                color_bgr = (255, 255, 255)  # ラベルリスト外の場合は白を適用\n",
        "\n",
        "            # マスク部分を半透明で色付け\n",
        "            mask_bgr = np.zeros_like(blended_image, dtype=np.uint8)\n",
        "            mask_bgr[mask == 1] = color_bgr  # マスク部分にBGRの色を適用\n",
        "\n",
        "            # 半透明度の設定\n",
        "            alpha = 0.5  # 半透明度\n",
        "            blended_image[mask == 1] = cv2.addWeighted(\n",
        "                blended_image[mask == 1], 1 - alpha, mask_bgr[mask == 1], alpha, 0\n",
        "            )  # マスクを半透明で重ねる\n",
        "\n",
        "            # 輪郭を追加\n",
        "            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cv2.drawContours(blended_image, contours, -1, (255, 255, 255), 2)  # 白い輪郭をBGRで描画\n",
        "\n",
        "        print(f\"The mask was applied.: {len(masks)} masks.\")\n",
        "\n",
        "        return blended_image\n",
        "    except Exception as e:\n",
        "        print(f\"apply_all_masks5 error.: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# オブジェクトカウント用のグローバル変数\n",
        "object_counter = 0\n",
        "\n",
        "def undo_box_selection(image_np, output_image, x_percent, y_percent):\n",
        "    global top_left, bottom_right, current_mask, object_counter\n",
        "\n",
        "    # デバッグメッセージを追加して出力画像の状態を確認\n",
        "    print(f\"Undo called for object {object_counter} with x_percent: {x_percent}, y_percent: {y_percent}\")\n",
        "\n",
        "    # オブジェクトカウンターに基づいて、使用する画像を決定\n",
        "    if object_counter == 0:\n",
        "        image_to_use = image_np  # オブジェクト1の場合\n",
        "    else:\n",
        "        image_to_use = output_image.copy()  # オブジェクト2以降ではoutput_imageのコピーを使用\n",
        "\n",
        "    # 画像が None の場合のエラーハンドリング\n",
        "    if image_to_use is None:\n",
        "        return gr.update(value=None), gr.update(value=\"No image available to reset.\")\n",
        "\n",
        "    # 座標のリセット\n",
        "    top_left = None\n",
        "    bottom_right = None\n",
        "    current_mask = None  # current_mask をクリア\n",
        "    print(\"Undo action: current_mask is reset to None\")\n",
        "\n",
        "    # 新しいoutput_imageを作成してstored_masksのみ描画\n",
        "    output_image_with_lines = apply_all_masks5(image_to_use, stored_masks)  # current_maskは含まない\n",
        "\n",
        "    # スライダーの値を強制的に+1にする（X座標の値を+1）\n",
        "    new_x_percent = min(100, x_percent + 1)  # 最大値は100に制限\n",
        "    print(f\"X slider updated to: {new_x_percent}\")\n",
        "\n",
        "    # スライダーの値を更新する\n",
        "    x_slider_update = gr.update(value=new_x_percent)\n",
        "\n",
        "    # スライダーの変更イベントをシミュレートして、画像を更新\n",
        "    output_image_with_lines = update_image_with_lines(output_image_with_lines, new_x_percent, y_percent)\n",
        "\n",
        "    # 再描画を強制し、重ね合わせが残らないようにする\n",
        "    print(\"Final output image with masks and lines ready for display.\")\n",
        "\n",
        "    # output_image_with_linesをGradioのインターフェースで表示する\n",
        "    return output_image_with_lines, gr.update(value=\"Box selection has been undone.\"), x_slider_update\n",
        "\n",
        "def update_image_with_lines(image, x_percent, y_percent):\n",
        "    global stored_masks, current_mask\n",
        "\n",
        "    # 画像がファイルパスで渡されている場合、画像を読み込む\n",
        "    if isinstance(image, str):\n",
        "        image_np = cv2.imread(image)  # ファイルパスを読み込む\n",
        "    elif isinstance(image, Image.Image):\n",
        "        image_np = np.array(image.convert(\"RGB\"))\n",
        "    else:\n",
        "        image_np = image  # すでに NumPy 配列ならそのまま使用\n",
        "\n",
        "    # セグメンテーションマスクを適用　#apply_all_masks2を使ってみる\n",
        "    output_image = apply_all_masks2(image_np, stored_masks + ([current_mask] if current_mask is not None else []))\n",
        "    return draw_lines_and_points(output_image, x_percent, y_percent, stored_points)\n",
        "\n",
        "def draw_lines_and_points(image, current_x, current_y, stored_points):\n",
        "    if image is None:\n",
        "        return \"Error: No image data\"\n",
        "\n",
        "    # 画像が PIL 形式か NumPy 配列かによってサイズの取得方法を変える\n",
        "    if isinstance(image, Image.Image):\n",
        "        width, height = image.size\n",
        "        processed_image = image.copy()  # PILの場合、コピーして描画\n",
        "    else:\n",
        "        height, width, _ = image.shape\n",
        "        processed_image = Image.fromarray(image)  # NumPyの場合、PILに変換\n",
        "\n",
        "    draw = ImageDraw.Draw(processed_image)\n",
        "\n",
        "    # 垂直線と水平線を描画 (現在のスライダー位置)\n",
        "    x_coord = int(width * (current_x / 100))\n",
        "    y_coord = int(height * (current_y / 100))\n",
        "    draw.line([(x_coord, 0), (x_coord, height)], fill=\"yellow\", width=3)\n",
        "    draw.line([(0, y_coord), (width, y_coord)], fill=\"yellow\", width=3)\n",
        "\n",
        "    # 記憶された座標に青い点（Add）と赤い点（Remove）を描画\n",
        "    for (x_percent, y_percent, label) in stored_points:\n",
        "        x_point = int(width * (x_percent / 100))\n",
        "        y_point = int(height * (y_percent / 100))\n",
        "        color = \"blue\" if label == 1 else \"red\"  # Addは青、Removeは赤\n",
        "        draw.ellipse([(x_point - 5, y_point - 5), (x_point + 5, y_point + 5)], fill=color, outline=color)\n",
        "\n",
        "    # 最後に NumPy 配列に戻す\n",
        "    return np.array(processed_image)\n",
        "\n",
        "def apply_all_masks(image, masks):\n",
        "    try:\n",
        "        blended_image = np.array(image, dtype=np.uint8)\n",
        "\n",
        "        for idx, mask in enumerate(masks):\n",
        "            if mask is None or mask.size == 0:\n",
        "                print(f\"The mask was not applied.: {idx}\")\n",
        "                continue\n",
        "\n",
        "            # 色ラベルから対応するBGRの色を選択 (最大20個まで対応)\n",
        "            if idx < len(color_labels):\n",
        "                # RBGに変換 (BGRの値からRとBを入れ替える)\n",
        "                color_bgr = color_labels[idx]  # 色ラベルリストからBGRの色をそのまま使用\n",
        "                color_rgb = (color_bgr[2], color_bgr[1], color_bgr[0])  # BとRを入れ替えてRGBに変換\n",
        "            else:\n",
        "                color_rgb = (255, 255, 255)  # ラベルリスト外の場合は白を適用\n",
        "\n",
        "            # マスク部分を半透明で色付け (RGBで色を適用)\n",
        "            mask_rgb = np.zeros_like(blended_image, dtype=np.uint8)\n",
        "            mask_rgb[mask == 1] = color_rgb  # マスク部分に色を適用 (RGB)\n",
        "\n",
        "            # 半透明度の設定\n",
        "            alpha = 0.5  # 半透明度\n",
        "            blended_image[mask == 1] = cv2.addWeighted(\n",
        "                blended_image[mask == 1], 1 - alpha, mask_rgb[mask == 1], alpha, 0\n",
        "            )  # マスクを半透明で重ねる\n",
        "\n",
        "            # 輪郭を追加\n",
        "            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cv2.drawContours(blended_image, contours, -1, (255, 255, 255), 2)  # 白い輪郭を描画\n",
        "\n",
        "        print(f\"The mask was applied.: {len(masks)} masks.\")\n",
        "\n",
        "        return blended_image\n",
        "    except Exception as e:\n",
        "        print(f\"apply_all_masks error.: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def reset_lines_on_add_object(image):\n",
        "    # 画像が NumPy 配列か PIL 形式か確認して NumPy 配列に変換\n",
        "    if isinstance(image, Image.Image):\n",
        "        image_np = np.array(image.convert(\"RGB\"))\n",
        "    else:\n",
        "        image_np = image  # すでに NumPy 配列の場合はそのまま使用\n",
        "\n",
        "    # 画像のサイズを取得\n",
        "    height, width, _ = image_np.shape\n",
        "\n",
        "    # 画像のコピーを作成し、中央に線を描画\n",
        "    processed_image = image_np.copy()\n",
        "    x_coord = width // 2\n",
        "    y_coord = height // 2\n",
        "\n",
        "    # 垂直線と水平線を描画 (黄色の線)\n",
        "    cv2.line(processed_image, (x_coord, 0), (x_coord, height), (255, 255, 0), 2)  # 垂直線\n",
        "    cv2.line(processed_image, (0, y_coord), (width, y_coord), (255, 255, 0), 2)  # 水平線\n",
        "\n",
        "    return processed_image\n",
        "\n",
        "def apply_all_masks2(image, masks):\n",
        "    try:\n",
        "        blended_image = np.array(image, dtype=np.uint8)\n",
        "\n",
        "        for idx, mask in enumerate(masks):\n",
        "            if mask is None or mask.size == 0:\n",
        "                print(f\"The mask was not applied.: {idx}\")\n",
        "                continue  # マスクがない場合はスキップ\n",
        "\n",
        "            # 色ラベルから対応するBGRの色を選択 (最大20個まで対応)\n",
        "            if idx < len(color_labels):\n",
        "                color_bgr = color_labels[idx]  # 色ラベルリストからBGRの色をそのまま使用\n",
        "            else:\n",
        "                color_bgr = (255, 255, 255)  # ラベルリスト外の場合は白を適用\n",
        "\n",
        "            # マスク部分を半透明で色付け\n",
        "            mask_bgr = np.zeros_like(blended_image, dtype=np.uint8)\n",
        "            mask_bgr[mask == 1] = color_bgr  # マスク部分にBGRの色を適用\n",
        "\n",
        "            # 半透明度の設定\n",
        "            alpha = 0.5  # 半透明度\n",
        "            blended_image[mask == 1] = cv2.addWeighted(\n",
        "                blended_image[mask == 1], 1 - alpha, mask_bgr[mask == 1], alpha, 0\n",
        "            )  # マスクを半透明で重ねる\n",
        "\n",
        "            # 輪郭を追加\n",
        "            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cv2.drawContours(blended_image, contours, -1, (255, 255, 255), 2)  # 白い輪郭をBGRで描画\n",
        "\n",
        "        print(f\"The mask was applied.: {len(masks)} masks.\")\n",
        "\n",
        "        return blended_image\n",
        "    except Exception as e:\n",
        "        print(f\"apply_all_masks2 error.: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def reset_lines_with_slider_positions(image, x_percent, y_percent):\n",
        "    # 画像が NumPy 配列か PIL 形式か確認して NumPy 配列に変換\n",
        "    if isinstance(image, Image.Image):\n",
        "        image_np = np.array(image.convert(\"RGB\"))\n",
        "    else:\n",
        "        image_np = image  # すでに NumPy 配列の場合はそのまま使用\n",
        "\n",
        "    # 画像のサイズを取得\n",
        "    height, width, _ = image_np.shape\n",
        "\n",
        "    # スライダーの値に基づいて座標を計算\n",
        "    x_coord = int(width * (x_percent / 100))\n",
        "    y_coord = int(height * (y_percent / 100))\n",
        "\n",
        "    # 画像のコピーを作成し、スライダーの位置に線を描画\n",
        "    processed_image = image_np.copy()\n",
        "    cv2.line(processed_image, (x_coord, 0), (x_coord, height), (255, 255, 0), 2)  # 垂直線\n",
        "    cv2.line(processed_image, (0, y_coord), (width, y_coord), (255, 255, 0), 2)  # 水平線\n",
        "\n",
        "    return processed_image\n",
        "\n",
        "stored_boxes = []  # ボックス情報を保存するリスト\n",
        "\n",
        "def complete_and_add_object(image, x_percent, y_percent):\n",
        "    global stored_masks, current_mask, stored_points, object_list, object_counter, current_object_points\n",
        "\n",
        "    if current_mask is not None:\n",
        "        # 現在のマスクを保存し、オブジェクトカウンターをインクリメント\n",
        "        stored_masks.append(current_mask)\n",
        "        object_counter += 1  # カウンターを1ずつ増やす\n",
        "        object_list.append(f\"Object {object_counter}\")  # カウンターを使ってオブジェクトを追加\n",
        "\n",
        "        # ボックス情報を保存（ここでtop_leftとbottom_rightを使う）\n",
        "        if top_left is not None and bottom_right is not None:\n",
        "            stored_boxes.append((top_left, bottom_right))  # ボックス情報を保存\n",
        "\n",
        "        # `current_mask` のリセットを遅らせ、トラッキングまで保持\n",
        "        stored_points = []  # 座標をリセット\n",
        "        current_mask = None  # 新しいオブジェクトのためにリセット\n",
        "        current_object_points = []  # 現在のオブジェクトの座標もリセット\n",
        "\n",
        "    # 画像が PIL 形式か NumPy 配列かを確認して適切に処理\n",
        "    if isinstance(image, Image.Image):\n",
        "        image_np = np.array(image.convert(\"RGB\"))\n",
        "    else:\n",
        "        image_np = image  # すでに NumPy 配列ならそのまま使用\n",
        "\n",
        "    # `apply_all_masks2` を使用して既存のマスクに新しいマスクを重ねて表示\n",
        "    output_image = apply_all_masks2(image_np, stored_masks)\n",
        "\n",
        "    # オブジェクトリストの更新\n",
        "    object_list_text = \"\\n\".join(object_list)\n",
        "\n",
        "    # 新しいオブジェクトの追加時にスライダーの値に基づいて線を表示\n",
        "    output_image_with_lines = reset_lines_with_slider_positions(output_image, x_percent, y_percent)\n",
        "\n",
        "    return output_image_with_lines, \"Moved to the segmentation of the new object.\", object_list_text\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def reset_all(image):\n",
        "    global stored_points, stored_masks, current_mask, object_list, last_used_coords, current_object_points, object_counter, uploaded_images, predictor\n",
        "\n",
        "    # 既存のリストや変数をリセット\n",
        "    stored_points = []\n",
        "    stored_masks = []\n",
        "    current_mask = None\n",
        "    object_list = []\n",
        "    last_used_coords = []\n",
        "    current_object_points = []\n",
        "    stored_boxes = []\n",
        "    object_counter = 0\n",
        "    uploaded_images = []  # アップロードされた画像リストをリセット\n",
        "\n",
        "    # フォルダの削除処理をまとめる\n",
        "    folders_to_delete = [\n",
        "        '/content/masks',\n",
        "        '/content/maskcolors',\n",
        "        '/content/images',\n",
        "        '/content/segmentation_results',\n",
        "        '/content/videos',\n",
        "        '/content/videos_reversed'\n",
        "    ]\n",
        "    for folder in folders_to_delete:\n",
        "        if os.path.exists(folder):\n",
        "            shutil.rmtree(folder)\n",
        "\n",
        "    # 動画ファイルの削除\n",
        "    video_output_path = '/content/output_video.mp4'\n",
        "    if os.path.exists(video_output_path):\n",
        "        os.remove(video_output_path)\n",
        "\n",
        "    # ZIPファイルの削除\n",
        "    zip_filepath_masks = '/content/segmented_images.zip'\n",
        "    zip_filepath_maskcolors = '/content/mask_color_images.zip'\n",
        "    if os.path.exists(zip_filepath_masks):\n",
        "        os.remove(zip_filepath_masks)\n",
        "    if os.path.exists(zip_filepath_maskcolors):\n",
        "        os.remove(zip_filepath_maskcolors)\n",
        "\n",
        "    # `predictor`の状態リセット\n",
        "    if 'predictor' in globals():\n",
        "        predictor.reset_state()\n",
        "\n",
        "    # テンポラリディレクトリやファイルを削除\n",
        "    temp_dir = tempfile.gettempdir()\n",
        "    for temp_file in os.listdir(temp_dir):\n",
        "        temp_file_path = os.path.join(temp_dir, temp_file)\n",
        "        try:\n",
        "            if os.path.isfile(temp_file_path):\n",
        "                os.unlink(temp_file_path)  # 一時ファイルを削除\n",
        "            elif os.path.isdir(temp_file_path):\n",
        "                shutil.rmtree(temp_file_path)  # 一時ディレクトリを削除\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to delete temporary file or directory {temp_file_path}: {str(e)}\")\n",
        "\n",
        "    # オブジェクトリストをリセットした際にテキスト表示も空にする\n",
        "    return image, \"\", \"\", \"\"\n",
        "\n",
        "def apply_segmentation_to_image(image):\n",
        "    global image_predictor\n",
        "\n",
        "    # 画像をセグメンテーションする\n",
        "    if isinstance(image, Image.Image):\n",
        "        image_np = np.array(image.convert(\"RGB\"))\n",
        "    else:\n",
        "        image_np = image\n",
        "\n",
        "    # セグメンテーション実行\n",
        "    image_predictor.set_image(image_np)\n",
        "    masks, scores, logits = image_predictor.predict(point_coords=np.array([[50, 50]]), point_labels=np.array([1]), multimask_output=True)\n",
        "\n",
        "    # 結果を適用\n",
        "    output_image = apply_all_masks(image_np, [masks[0]])\n",
        "\n",
        "    return output_image\n",
        "\n",
        "# フォルダ作成用の関数\n",
        "def create_mask_folder():\n",
        "    mask_folder = '/content/masks'\n",
        "    if not os.path.exists(mask_folder):\n",
        "        os.makedirs(mask_folder)\n",
        "    return mask_folder\n",
        "\n",
        "# 画像を保存する関数\n",
        "def save_masked_image_to_disk(image_np, filename):\n",
        "    img_pil = Image.fromarray(image_np)\n",
        "    img_pil.save(filename, format=\"JPEG\")\n",
        "\n",
        "# ZIPファイルに保存されたマスク画像をまとめる関数\n",
        "def create_zip_from_masks(zip_filename=\"segmented_images.zip\"):\n",
        "    mask_folder = create_mask_folder()\n",
        "    zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "    with zipfile.ZipFile(zip_filepath, 'w') as zip_file:\n",
        "        for root, _, files in os.walk(mask_folder):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zip_file.write(file_path, arcname=file)  # ZIPファイル内の相対パスを保持\n",
        "\n",
        "    return zip_filepath\n",
        "\n",
        "# フォルダ作成用の関数\n",
        "def create_mask_folder():\n",
        "    print(\"create_mask_folder called\")  # デバッグメッセージ\n",
        "    mask_folder = '/content/masks'\n",
        "    if not os.path.exists(mask_folder):\n",
        "        os.makedirs(mask_folder)\n",
        "        print(f\"Folder created at: {mask_folder}\")  # フォルダ作成確認\n",
        "    return mask_folder\n",
        "\n",
        "# マスクカラー画像用フォルダ作成関数\n",
        "def create_mask_color_folder():\n",
        "    print(\"create_mask_color_folder called\")  # デバッグメッセージ\n",
        "    mask_color_folder = '/content/maskcolors'\n",
        "    if not os.path.exists(mask_color_folder):\n",
        "        os.makedirs(mask_color_folder)\n",
        "        print(f\"Folder created at: {mask_color_folder}\")  # フォルダ作成確認\n",
        "    return mask_color_folder\n",
        "\n",
        "# 画像を保存する関数\n",
        "def save_masked_image_to_disk(image_np, filename):\n",
        "    print(f\"save_masked_image_to_disk called for {filename}\")  # デバッグメッセージ\n",
        "    img_pil = Image.fromarray(image_np)\n",
        "    img_pil.save(filename, format=\"JPEG\")\n",
        "    print(f\"Image saved to {filename}\")  # 保存確認\n",
        "\n",
        "def save_mask_color_image_to_disk(image_np, masks, filename):\n",
        "    print(f\"save_mask_color_image_to_disk called for {filename}\")  # デバッグメッセージ\n",
        "    \"\"\"マスクカラー画像を生成し、黒背景に描画して保存\"\"\"\n",
        "    mask_color_image = np.zeros_like(image_np, dtype=np.uint8)  # 黒背景を作成\n",
        "\n",
        "    for idx, mask in enumerate(masks):\n",
        "        if mask is None or mask.size == 0:\n",
        "            print(f\"The mask was not applied.: {idx}\")\n",
        "            continue\n",
        "\n",
        "        # マスクが2次元か確認し、もし次元が1次元であればリサイズ\n",
        "        if mask.ndim != 2:\n",
        "            mask = np.squeeze(mask)  # マスクが2次元になるように次元を縮小\n",
        "\n",
        "        # 色ラベルから対応する色を選択\n",
        "        if idx < len(color_labels):\n",
        "            color = color_labels[idx]  # 色ラベルリストから色を選択\n",
        "        else:\n",
        "            color = (255, 255, 255)  # ラベルリスト外の場合は白を適用\n",
        "\n",
        "        # マスク部分を完全に塗りつぶす\n",
        "        mask_color_image[mask == 1] = color  # マスク部分に色を適用 (透過なし)\n",
        "\n",
        "    # 保存\n",
        "    img_pil = Image.fromarray(mask_color_image)\n",
        "    img_pil.save(filename, format=\"PNG\")   # ここをJPEGからPNGに変更\n",
        "    print(f\"Mask color image saved to {filename}\")  # 保存確認\n",
        "\n",
        "# ZIPファイルに保存されたマスク画像をまとめる関数\n",
        "def create_zip_from_masks(zip_filename=\"segmented_images.zip\"):\n",
        "    segmentation_results_folder = '/content/segmentation_results'\n",
        "    zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "    with zipfile.ZipFile(zip_filepath, 'w') as zip_file:\n",
        "        for root, _, files in os.walk(segmentation_results_folder):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zip_file.write(file_path, arcname=file)  # ZIPファイル内の相対パスを保持\n",
        "\n",
        "    return zip_filepath\n",
        "\n",
        "# マスクカラーの画像をまとめるZIPファイル生成関数\n",
        "def create_zip_from_maskcolors(zip_filename=\"mask_color_images.zip\"):\n",
        "    print(\"create_zip_from_maskcolors called\")  # デバッグメッセージ\n",
        "    mask_color_folder = create_mask_color_folder()\n",
        "    zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "    with zipfile.ZipFile(zip_filepath, 'w') as zip_file:\n",
        "        for root, _, files in os.walk(mask_color_folder):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zip_file.write(file_path, arcname=file)  # ZIPファイル内の相対パスを保持\n",
        "\n",
        "    print(f\"ZIP file for mask colors created at {zip_filepath}\")  # ZIPファイル作成確認\n",
        "    return zip_filepath\n",
        "\n",
        "import svgwrite\n",
        "\n",
        "# SVGファイルを生成する関数\n",
        "def create_svg_from_mask(image_np, masks, filename):\n",
        "    height, width, _ = image_np.shape\n",
        "    dwg = svgwrite.Drawing(filename, profile='tiny', size=(width, height))\n",
        "\n",
        "    # 指定されたマスクカラーを使用してベクター化\n",
        "    for idx, mask in enumerate(masks):\n",
        "        if mask is None or mask.size == 0:\n",
        "            continue\n",
        "\n",
        "        # 対応するカラーの取得（RGBをそのまま使用）\n",
        "        color_rgb = color_labels[idx] if idx < len(color_labels) else (255, 255, 255)\n",
        "        hex_color = '#{:02x}{:02x}{:02x}'.format(color_rgb[0], color_rgb[1], color_rgb[2])\n",
        "\n",
        "        # 輪郭の検出と追加\n",
        "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for contour in contours:\n",
        "            points = [(int(point[0][0]), int(point[0][1])) for point in contour]\n",
        "            dwg.add(dwg.polygon(points, fill=hex_color))\n",
        "\n",
        "    # SVGファイルの保存\n",
        "    dwg.save()\n",
        "    print(f\"SVG file created: {filename}\")\n",
        "\n",
        "# SVGファイルをまとめるZIPファイル生成関数\n",
        "def create_zip_from_svgs(zip_filename=\"mask_svgs.zip\"):\n",
        "    svg_folder = '/content/mask_svgs'\n",
        "    zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "    with zipfile.ZipFile(zip_filepath, 'w') as zip_file:\n",
        "        for root, _, files in os.walk(svg_folder):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zip_file.write(file_path, arcname=file)  # ZIPファイル内の相対パスを保持\n",
        "\n",
        "    print(f\"ZIP file for SVGs created at {zip_filepath}\")\n",
        "    return zip_filepath\n",
        "\n",
        "# グレースケールの色ラベルをRGB形式で定義\n",
        "grayscale_labels = [\n",
        "    (255, 255, 255), (248, 248, 248), (237, 237, 237), (226, 226, 226),\n",
        "    (215, 215, 215), (204, 204, 204), (193, 193, 193), (182, 182, 182),\n",
        "    (171, 171, 171), (160, 160, 160), (149, 149, 149), (138, 138, 138),\n",
        "    (127, 127, 127), (116, 116, 116), (105, 105, 105), (94, 94, 94),\n",
        "    (83, 83, 83), (72, 72, 72), (61, 61, 61), (50, 50, 50)\n",
        "]\n",
        "\n",
        "# グレースケールマスクを保存する関数（RGBとして処理）\n",
        "def save_grayscale_mask(image_np, masks, filename):\n",
        "    print(f\"save_grayscale_mask called for {filename}\")\n",
        "    \"\"\"グレースケールマスク画像を生成し、黒背景に描画して保存\"\"\"\n",
        "\n",
        "    # 黒背景を作成（3次元のRGB画像と同じ形にする）\n",
        "    grayscale_mask_image = np.zeros_like(image_np, dtype=np.uint8)\n",
        "    print(f\"Initial grayscale mask created with shape: {grayscale_mask_image.shape}\")\n",
        "\n",
        "    for idx, mask in enumerate(masks):\n",
        "        if mask is None or mask.size == 0:\n",
        "            print(f\"The mask was not applied.: {idx}\")\n",
        "            continue\n",
        "\n",
        "        # マスクが2次元か確認し、もし次元が1次元であればリサイズ\n",
        "        if mask.ndim != 2:\n",
        "            mask = np.squeeze(mask)  # マスクが2次元になるように次元を縮小\n",
        "        print(f\"Processing mask {idx} with shape {mask.shape}\")\n",
        "\n",
        "        # グレースケールラベルから対応する色（RGB形式）を選択\n",
        "        if idx < len(grayscale_labels):\n",
        "            grayscale_value = grayscale_labels[idx]  # RGBのグレースケールラベルを適用\n",
        "        else:\n",
        "            grayscale_value = (10, 10, 10)  # ラベルリスト外の場合は(10, 10, 10)を適用\n",
        "\n",
        "        # マスク部分にグレースケール値を適用（RGB形式で完全に塗りつぶす）\n",
        "        grayscale_mask_image[mask == 1] = grayscale_value\n",
        "\n",
        "    # 保存\n",
        "    img_pil = Image.fromarray(grayscale_mask_image)\n",
        "    img_pil.save(filename, format=\"PNG\")\n",
        "    print(f\"Grayscale mask image saved to {filename}\")\n",
        "\n",
        "# グレースケールマスク画像をまとめるZIPファイル生成関数\n",
        "def create_zip_from_grayscale_masks(zip_filename=\"grayscale_masks.zip\"):\n",
        "    grayscale_folder = '/content/grayscale_masks'\n",
        "    zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "    if not os.path.exists(grayscale_folder):\n",
        "        os.makedirs(grayscale_folder)\n",
        "\n",
        "    with zipfile.ZipFile(zip_filepath, 'w') as zip_file:\n",
        "        for root, _, files in os.walk(grayscale_folder):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zip_file.write(file_path, arcname=file)  # ZIPファイル内の相対パスを保持\n",
        "\n",
        "    print(f\"ZIP file for grayscale masks created at {zip_filepath}\")\n",
        "    return zip_filepath\n",
        "\n",
        "def apply_all_masks3(image, masks, frame_idx, svg_folder):\n",
        "    global starting_index  # starting_indexをグローバル変数として宣言\n",
        "    try:\n",
        "        blended_image = np.array(image, dtype=np.uint8)\n",
        "        image_height, image_width = blended_image.shape[:2]\n",
        "\n",
        "\n",
        "        # SVGファイルの保存先を設定\n",
        "        svg_filename = os.path.join(svg_folder, f\"mask{starting_index + frame_idx:04}.svg\")\n",
        "        dwg = svgwrite.Drawing(svg_filename, profile='tiny', size=(image_width, image_height))\n",
        "        dwg.add(dwg.rect(insert=(0, 0), size=(image_width, image_height), fill='black'))  # 背景を黒に設定\n",
        "\n",
        "        # マスクの適用処理\n",
        "        mask_applied = False  # マスクが適用されたかを確認するためのフラグ\n",
        "        for idx, mask in enumerate(masks):\n",
        "            if mask is None or mask.size == 0:\n",
        "                print(f\"The mask at index {idx} is None or empty. Skipping...\")\n",
        "                continue  # マスクがない場合はスキップ\n",
        "\n",
        "            # マスクがbool型の場合、uint8に変換\n",
        "            if mask.dtype == bool:\n",
        "                mask = mask.astype(np.uint8)\n",
        "\n",
        "            # デバッグ出力: マスクの状態を確認\n",
        "            print(f\"Original mask at index {idx}: {mask}\")\n",
        "\n",
        "            # マスクのサイズを画像に合わせてリサイズ\n",
        "            if mask.ndim > 2:\n",
        "                mask = mask.squeeze()  # 余計な次元を削除\n",
        "\n",
        "            mask_resized = cv2.resize(mask, (image_width, image_height))\n",
        "\n",
        "            # デバッグ出力: リサイズ後のマスクを確認\n",
        "            print(f\"Resized mask at index {idx}: {mask_resized}\")\n",
        "\n",
        "            # デバッグ出力: マスクと画像のサイズを確認\n",
        "            print(f\"Mask size: {mask_resized.shape}, Image size: {blended_image.shape}\")\n",
        "\n",
        "            # マスクがすべて0の場合スキップ\n",
        "            if np.all(mask_resized == 0):\n",
        "                print(f\"Mask at index {idx} contains only zeros. Skipping...\")\n",
        "                continue\n",
        "\n",
        "            # 色ラベルから対応するBGRの色を選択 (最大20個まで対応)\n",
        "            if idx < len(color_labels):\n",
        "                color_bgr = color_labels[idx]  # 色ラベルリストからBGRの色をそのまま使用\n",
        "            else:\n",
        "                color_bgr = (255, 255, 255)  # ラベルリスト外の場合は白を適用\n",
        "\n",
        "            # デバッグ出力: 使用する色を確認\n",
        "            print(f\"Color BGR at index {idx}: {color_bgr}\")\n",
        "\n",
        "            hex_color = '#{:02x}{:02x}{:02x}'.format(color_bgr[0], color_bgr[1], color_bgr[2])  # RGBカラーをそのまま使用\n",
        "\n",
        "            # 2次元のマスクを3次元に拡張する\n",
        "            mask_bgr = np.zeros_like(blended_image, dtype=np.uint8)\n",
        "            mask_3d = np.repeat(mask_resized[:, :, np.newaxis], 3, axis=2)  # 2次元マスクを3チャンネルに拡張\n",
        "\n",
        "            # デバッグ出力: マスクの拡張後を確認\n",
        "            print(f\"Expanded mask at index {idx}: {mask_3d.shape}\")\n",
        "\n",
        "            # マスク部分を色付け\n",
        "            mask_bgr[mask_resized == 1] = np.array(color_bgr)\n",
        "\n",
        "            # デバッグ出力: 色付け後のマスクを確認\n",
        "            print(f\"Mask BGR at index {idx}: {mask_bgr}\")\n",
        "\n",
        "            # 半透明度の設定\n",
        "            alpha = 0.5  # 半透明度\n",
        "            blended_image[mask_resized == 1] = cv2.addWeighted(\n",
        "                blended_image[mask_resized == 1], 1 - alpha, mask_bgr[mask_resized == 1], alpha, 0\n",
        "            )\n",
        "\n",
        "            # 輪郭を追加\n",
        "            contours, _ = cv2.findContours(mask_resized.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cv2.drawContours(blended_image, contours, -1, (255, 255, 255), 2)  # 白い輪郭を描画\n",
        "\n",
        "            # 輪郭をSVGファイルに追加\n",
        "            contours, _ = cv2.findContours(mask_resized.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            for contour in contours:\n",
        "                points = [(int(point[0][0]), int(point[0][1])) for point in contour]\n",
        "                dwg.add(dwg.polygon(points, fill=hex_color))\n",
        "\n",
        "            # # SVGファイルを保存\n",
        "            # dwg.save()\n",
        "            # print(f\"SVG file created for frame {frame_idx}: {svg_filename}\")\n",
        "            # # --- 追加終了 ---\n",
        "\n",
        "        # マスクが無い場合でも背景のみのSVGファイルを保存\n",
        "        if mask_applied or not mask_applied:\n",
        "            dwg.save()\n",
        "            print(f\"SVG file created for frame {frame_idx}: {svg_filename}\")\n",
        "\n",
        "        print(f\"The mask was applied.: {len(masks)} masks.\")\n",
        "\n",
        "        return blended_image\n",
        "    except Exception as e:\n",
        "        print(f\"apply_all_masks3 error: {str(e)} at mask index {idx}\")\n",
        "        raise\n",
        "\n",
        "# フレームの数を確認する関数\n",
        "def count_frames(video_dir):\n",
        "    frame_names = [p for p in os.listdir(video_dir) if os.path.splitext(p)[-1].lower() in [\".jpg\", \".jpeg\"]]\n",
        "    frame_names.sort(key=lambda p: int(os.path.splitext(p)[0]))\n",
        "    print(f\"Total number of frames: {len(frame_names)}\")\n",
        "    return frame_names\n",
        "\n",
        "def create_mask_from_box(box, image_shape):\n",
        "    \"\"\"ボックスの座標からマスクを作成します\"\"\"\n",
        "    mask = np.zeros(image_shape[:2], dtype=np.float32)\n",
        "    x_min, y_min, x_max, y_max = map(int, box)\n",
        "    mask[y_min:y_max, x_min:x_max] = 1.0\n",
        "    return mask\n",
        "\n",
        "def process_video_with_propagation(video_path, last_used_coords, stored_boxes, image_index):\n",
        "    # フォルダの作成\n",
        "    if not os.path.exists(\"./videos\"):\n",
        "        os.makedirs(\"./videos\")\n",
        "\n",
        "    # FFmpegを使って動画をJPEGフレームに変換\n",
        "    os.system(f\"ffmpeg -i {video_path} -q:v 2 -start_number 0 ./videos/%05d.jpg\")\n",
        "\n",
        "    # フレームの数を確認\n",
        "    video_dir = \"./videos\"\n",
        "    frame_names = count_frames(video_dir)\n",
        "\n",
        "    # セグメンテーション処理を行うための状態を初期化\n",
        "    inference_state = predictor.init_state(video_path=video_dir)\n",
        "    predictor.reset_state(inference_state)\n",
        "\n",
        "    # 指定されたimage_indexに対応するフレームを読み込み\n",
        "    selected_frame_path = os.path.join(video_dir, frame_names[image_index - 1])\n",
        "    image_np = np.array(Image.open(selected_frame_path))\n",
        "\n",
        "    if image_np is not None:\n",
        "        frame_height, frame_width = image_np.shape[:2]\n",
        "\n",
        "        for obj_idx, (top_left, bottom_right) in enumerate(stored_boxes):\n",
        "            obj_id = obj_idx + 1\n",
        "\n",
        "            box = np.array([\n",
        "                int(frame_width * (top_left[0] / 100)), int(frame_height * (top_left[1] / 100)),\n",
        "                int(frame_width * (bottom_right[0] / 100)), int(frame_height * (bottom_right[1] / 100))\n",
        "            ], dtype=np.float32)\n",
        "\n",
        "            if obj_idx < len(last_used_coords):\n",
        "                points_info = last_used_coords[obj_idx]\n",
        "                x_percent, y_percent, label_value = points_info\n",
        "                points = np.array([[int(frame_width * (x_percent / 100)), int(frame_height * (y_percent / 100))]], dtype=np.float32)\n",
        "                labels = np.array([label_value], dtype=np.int32)\n",
        "            else:\n",
        "                points = None\n",
        "                labels = None\n",
        "\n",
        "            predictor.add_new_points_or_box(\n",
        "                inference_state=inference_state,\n",
        "                frame_idx=image_index - 1,\n",
        "                obj_id=obj_id,\n",
        "                points=points,\n",
        "                labels=labels,\n",
        "                box=box\n",
        "            )\n",
        "    else:\n",
        "        raise ValueError(f\"Failed to load the frame at {selected_frame_path}.\")\n",
        "\n",
        "    # 順方向のマスク伝播（指定フレームから最後のフレームまで）\n",
        "    video_segments = {}\n",
        "    for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):\n",
        "        video_segments[out_frame_idx] = {\n",
        "            out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
        "            for i, out_obj_id in enumerate(out_obj_ids)\n",
        "        }\n",
        "\n",
        "        # 伝播が最後のフレームに到達したらループを抜ける\n",
        "        if out_frame_idx >= len(frame_names) - 1:\n",
        "            break\n",
        "\n",
        "    # 逆方向の伝播を実現するために、フレームを逆順にする\n",
        "    reversed_frame_indices = list(range(0, image_index))[::-1]  # [image_index-1, image_index-2, ..., 0]\n",
        "\n",
        "    # 逆順のフレーム名リストを作成\n",
        "    reversed_frame_names = [frame_names[idx] for idx in reversed_frame_indices]\n",
        "\n",
        "    # 新しいフォルダを作成して逆順フレームを保存\n",
        "    reversed_video_dir = \"./videos_reversed\"\n",
        "    if not os.path.exists(reversed_video_dir):\n",
        "        os.makedirs(reversed_video_dir)\n",
        "\n",
        "    for i, frame_name in enumerate(reversed_frame_names):\n",
        "        reversed_frame_path = os.path.join(video_dir, frame_name)\n",
        "        new_frame_path = os.path.join(reversed_video_dir, f\"{i:05d}.jpg\")\n",
        "        os.system(f\"cp {reversed_frame_path} {new_frame_path}\")\n",
        "\n",
        "    # 逆順フレームのディレクトリでセグメンテーション伝播を実行\n",
        "    reversed_inference_state = predictor.init_state(video_path=reversed_video_dir)\n",
        "    predictor.reset_state(reversed_inference_state)\n",
        "\n",
        "    # 再度、指定されたフレームから設定を追加\n",
        "    for obj_idx, (top_left, bottom_right) in enumerate(stored_boxes):\n",
        "        obj_id = obj_idx + 1\n",
        "\n",
        "        # ボックスの再計算\n",
        "        box = np.array([\n",
        "            int(frame_width * (top_left[0] / 100)), int(frame_height * (top_left[1] / 100)),\n",
        "            int(frame_width * (bottom_right[0] / 100)), int(frame_height * (bottom_right[1] / 100))\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        # ポイントとラベルの再設定\n",
        "        if obj_idx < len(last_used_coords):\n",
        "            points_info = last_used_coords[obj_idx]\n",
        "            x_percent, y_percent, label_value = points_info\n",
        "            points = np.array([[int(frame_width * (x_percent / 100)), int(frame_height * (y_percent / 100))]], dtype=np.float32)\n",
        "            labels = np.array([label_value], dtype=np.int32)\n",
        "        else:\n",
        "            points = None\n",
        "            labels = None\n",
        "\n",
        "        # デバッグ出力\n",
        "        print(f\"Setting obj_id {obj_id} with box {box}, points {points}, and labels {labels} for reversed propagation.\")\n",
        "\n",
        "        predictor.add_new_points_or_box(\n",
        "            inference_state=reversed_inference_state,\n",
        "            frame_idx=0,  # 逆順の最初のフレームはフレームインデックス0\n",
        "            obj_id=obj_id,\n",
        "            points=points,\n",
        "            labels=labels,\n",
        "            box=box\n",
        "        )\n",
        "\n",
        "    # 逆順のフレーム伝播\n",
        "    reversed_video_segments = {}\n",
        "    for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(reversed_inference_state):\n",
        "        reversed_video_segments[out_frame_idx] = {\n",
        "            out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
        "            for i, out_obj_id in enumerate(out_obj_ids)\n",
        "        }\n",
        "\n",
        "        # 伝播が逆方向の最後のフレーム（実際の最初のフレーム）に到達したらループを抜ける\n",
        "        if out_frame_idx >= len(reversed_frame_names) - 1:\n",
        "            break\n",
        "\n",
        "    # 結果を元の順序に戻す\n",
        "    for rev_idx, frame_idx in enumerate(reversed_frame_indices):\n",
        "        video_segments[frame_idx] = reversed_video_segments[rev_idx]\n",
        "\n",
        "    # マスク保存用のフォルダを作成\n",
        "    mask_folder = '/content/segmentation_results'\n",
        "    if not os.path.exists(mask_folder):\n",
        "        os.makedirs(mask_folder)\n",
        "\n",
        "    # マスクカラー画像保存用フォルダを作成\n",
        "    mask_color_folder = create_mask_color_folder()\n",
        "\n",
        "    # グレースケールマスク保存用のフォルダを作成\n",
        "    grayscale_folder = '/content/grayscale_masks'\n",
        "    if not os.path.exists(grayscale_folder):\n",
        "        os.makedirs(grayscale_folder)\n",
        "\n",
        "    segmented_image_paths = []\n",
        "\n",
        "    # SVGファイル保存用フォルダを作成\n",
        "    svg_folder = '/content/mask_svgs'\n",
        "    if not os.path.exists(svg_folder):\n",
        "        os.makedirs(svg_folder)\n",
        "\n",
        "    # 各フレームの結果を表示し、マスクを保存\n",
        "    plt.close(\"all\")\n",
        "    for frame_idx, frame_name in enumerate(frame_names):\n",
        "        image_np = np.array(Image.open(os.path.join(video_dir, frame_name)))\n",
        "\n",
        "        if image_np is None:\n",
        "            print(f\"Failed to load image at frame {frame_name}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        masks_to_apply = video_segments.get(frame_idx, {}).values()\n",
        "        output_image = apply_all_masks3(image_np, list(masks_to_apply), frame_idx, svg_folder)  # svg_folderを追加\n",
        "\n",
        "        filename = f\"segmented_image_{starting_index + frame_idx:04}.jpg\"\n",
        "        filepath = os.path.join(mask_folder, filename)\n",
        "        save_masked_image_to_disk(output_image, filepath)\n",
        "\n",
        "        mask_color_filename = f\"mask{starting_index + frame_idx:04}.png\"\n",
        "        mask_color_filepath = os.path.join(mask_color_folder, mask_color_filename)\n",
        "        save_mask_color_image_to_disk(image_np, masks_to_apply, mask_color_filepath)\n",
        "\n",
        "        grayscale_filename = f\"mask{starting_index + frame_idx:04}.png\"\n",
        "        grayscale_filepath = os.path.join(grayscale_folder, grayscale_filename)\n",
        "        save_grayscale_mask(image_np, masks_to_apply, grayscale_filepath)\n",
        "\n",
        "        segmented_image_paths.append(filepath)\n",
        "\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.title(f\"Frame {frame_idx}\")\n",
        "        plt.imshow(output_image)\n",
        "        plt.show()\n",
        "\n",
        "    print(f\"Segmentation results saved to {mask_folder}\")\n",
        "\n",
        "    zip_filepath_masks = create_zip_from_masks()\n",
        "    zip_filepath_maskcolors = create_zip_from_maskcolors()\n",
        "    zip_filepath_svgs = create_zip_from_svgs()  # SVGのZIPファイル作成\n",
        "    zip_filepath_grayscale = create_zip_from_grayscale_masks()  # グレースケールマスクZIP\n",
        "\n",
        "    return zip_filepath_masks, zip_filepath_maskcolors, zip_filepath_svgs, zip_filepath_grayscale, segmented_image_paths, \"Segmentation has been applied to all images.\"\n",
        "\n",
        "# Gradioインターフェース\n",
        "def gradio_interface():\n",
        "    global object_counter\n",
        "    object_counter = 0  # 初期状態ではオブジェクト0からスタート\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"## SAM2 GUI for Img Seq\")\n",
        "        gr.Markdown(\"### How to Reset\")\n",
        "        gr.Markdown(\n",
        "            \"To reset the interface, return to the Colab notebook and go to \"\n",
        "            \"**Runtime > Disconnect and delete runtime**, then re-run all cells by selecting \"\n",
        "            \"**Runtime > Run all**.\"\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                upload_btn = gr.Files(label=\"Upload Images\", file_count=\"multiple\", file_types=[\"image\"])\n",
        "                upload_status = gr.Textbox(label=\"Upload Status\")\n",
        "                uploaded_images_gallery = gr.Gallery(label=\"Uploaded Images\", show_label=True)\n",
        "                slider = gr.Slider(label=\"Frame Selection\", minimum=1, maximum=1, step=1, value=1)\n",
        "                select_btn = gr.Button(\"Perform Segmentation on This Image\")\n",
        "                displayed_image = gr.Image(label=\"Selected Image\")\n",
        "                score_output = gr.Textbox(label=\"Mask Score\")\n",
        "                object_list_display = gr.Textbox(label=\"Object List\")\n",
        "\n",
        "            with gr.Column():\n",
        "                x_slider = gr.Slider(label=\"X Coordinate (%)\", minimum=0, maximum=100, value=50, step=1)\n",
        "                y_slider = gr.Slider(label=\"Y Coordinate (%)\", minimum=0, maximum=100, value=50, step=1)\n",
        "                # Set Top Left と Set Bottom Right を横並びにする\n",
        "                with gr.Row():\n",
        "                    top_left_btn = gr.Button(\"Set Top Left\")\n",
        "                    bottom_right_btn = gr.Button(\"Set Bottom Right\")\n",
        "                    undo_btn = gr.Button(\"Undo Box Selection\")  # Undo ボタンを追加\n",
        "                complete_and_add_btn = gr.Button(\"Complete Segmentation or Add Next Object\")\n",
        "                output_image = gr.Image(label=\"Segmentation Result\")\n",
        "                start_tracking_btn = gr.Button(\"Start Tracking\")\n",
        "                all_segmented_images = gr.Gallery(label=\"Segmentation Results for All Images\")\n",
        "                download_zip_masks_output = gr.File(label=\"Images with mask overlay(ZIP)\")\n",
        "                download_zip_maskcolors_output = gr.File(label=\"Black background mask(ZIP)\")\n",
        "                download_zip_svgs_output = gr.File(label=\"Vector mask (SVG) ZIP\")\n",
        "                download_zip_grayscale_output = gr.File(label=\"Grayscale masks (ZIP)\")\n",
        "\n",
        "        # 複数画像のアップロードイベント（アップロード画像ギャラリーを追加）\n",
        "        upload_btn.upload(\n",
        "            fn=upload_images,\n",
        "            inputs=upload_btn,\n",
        "            outputs=[upload_status, slider, displayed_image, uploaded_images_gallery]  # ギャラリーを追加\n",
        "        )\n",
        "\n",
        "\n",
        "        # スライダーで画像を表示\n",
        "        slider.change(fn=display_image, inputs=slider, outputs=displayed_image)\n",
        "\n",
        "        # スライダーが動いたときに画像にラインを描画\n",
        "        x_slider.change(fn=lambda image, x, y: update_image_with_lines(image, x, y),\n",
        "                        inputs=[displayed_image, x_slider, y_slider],\n",
        "                        outputs=output_image)\n",
        "        y_slider.change(fn=lambda image, x, y: update_image_with_lines(image, x, y),\n",
        "                        inputs=[displayed_image, x_slider, y_slider],\n",
        "                        outputs=output_image)\n",
        "\n",
        "        top_left_btn.click(fn=set_top_left, inputs=[x_slider, y_slider], outputs=score_output)\n",
        "        # 'displayed_image' も 'inputs' に含めて、set_bottom_right に渡す\n",
        "        bottom_right_btn.click(\n",
        "            fn=set_bottom_right,\n",
        "            inputs=[x_slider, y_slider, displayed_image],  # 画像データも追加\n",
        "            outputs=[output_image, score_output]  # 画像とメッセージを別々に出力\n",
        "        )\n",
        "\n",
        "        # 「この画像でセグメンテーションを行う」ボタンが押されたとき\n",
        "        select_btn.click(fn=update_result_on_select, inputs=slider, outputs=[displayed_image, output_image])\n",
        "\n",
        "        # Undoボタンのクリック時の挙動を設定、object_counterに応じて画像をリセット\n",
        "        undo_btn.click(\n",
        "            undo_box_selection,\n",
        "            inputs=[displayed_image, output_image, x_slider, y_slider],\n",
        "            outputs=[output_image, score_output, x_slider]  # x_sliderも更新\n",
        "        )\n",
        "\n",
        "        # セグメンテーションを完了し、次のオブジェクトを追加\n",
        "        complete_and_add_btn.click(fn=complete_and_add_object, inputs=[displayed_image, x_slider, y_slider], outputs=[output_image, score_output, object_list_display])\n",
        "\n",
        "        # # トラッキングを開始ボタンが押された時、全ての画像にセグメンテーションを適用\n",
        "        # start_tracking_btn.click(fn=lambda: process_video_with_propagation(\"/content/output_video.mp4\", last_used_coords, stored_boxes, image_index), inputs=[], outputs=[download_zip_masks_output, download_zip_maskcolors_output, all_segmented_images])\n",
        "        start_tracking_btn.click(\n",
        "            fn=lambda image_index: process_video_with_propagation(\"/content/output_video.mp4\", last_used_coords, stored_boxes, image_index),\n",
        "            inputs=[slider],  # スライダーからの入力を受け取る\n",
        "            outputs=[download_zip_masks_output, download_zip_maskcolors_output, download_zip_svgs_output, download_zip_grayscale_output, all_segmented_images]\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Gradioアプリの起動\n",
        "gradio_interface().launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_faWctoSbUu"
      },
      "source": [
        "Copyright (c) 2024 Satoru Muro. All rights reserved.\n",
        "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
        "1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
        "2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
        "\n",
        "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
